{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "import os\n",
    "from joblib import dump\n",
    "import pickle as pkl\n",
    "import pickle\n",
    "import itertools\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score, classification_report, precision_recall_curve\n",
    "from sklearn.metrics import make_scorer, fbeta_score,  mean_squared_error, r2_score, f1_score\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.feature_selection import RFECV\n",
    "from sklearn.model_selection import StratifiedKFold, RandomizedSearchCV, GridSearchCV, train_test_split, StratifiedShuffleSplit\n",
    "from sklearn import datasets\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "import xgboost as xgb\n",
    "from xgboost import XGBClassifier, plot_importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "train_df = pd.read_csv('/work/SarahHvidAndersen#6681/DataScience_project/data/train_df.csv')\n",
    "eval_df = pd.read_csv('/work/SarahHvidAndersen#6681/DataScience_project/data/eval_df.csv')\n",
    "test_df = pd.read_csv('/work/SarahHvidAndersen#6681/DataScience_project/data/test_df.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop labels column\n",
    "print(train_df['Attack'].value_counts())\n",
    "print(train_df['Label'].value_counts())\n",
    "\n",
    "train_df = train_df.drop('Label', axis=1)\n",
    "eval_df = eval_df.drop('Label', axis=1)\n",
    "test_df = test_df.drop('Label', axis=1)\n",
    "\n",
    "X_train = train_df.drop(['Attack'], axis=1)\n",
    "y_train = train_df['Attack']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# correlation\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(train_df.corr(), cmap='coolwarm', annot=False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the correlation matrix\n",
    "corr = train_df.corr()\n",
    "\n",
    "# Extract correlations with 'Attack' greater than a threshold\n",
    "threshold = 0.2  # Adjust this threshold to your needs\n",
    "high_corr = corr['Attack'][corr['Attack'].abs() > threshold].drop('Attack')  # Exclude the correlation of 'Attack' with itself\n",
    "\n",
    "# Convert to DataFrame for plotting\n",
    "high_corr_df = pd.DataFrame(high_corr.sort_values(ascending=False))\n",
    "high_corr_df.columns = ['Correlation']\n",
    "\n",
    "# Plot\n",
    "plt.figure(figsize=(8, len(high_corr_df) / 2))  # Adjust the figure size dynamically based on the number of features\n",
    "sns.heatmap(high_corr_df, annot=True, cmap='coolwarm', vmin=-1, vmax=1, fmt=\".2f\")\n",
    "plt.title('Correlations with \"Attack\"')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting up the figure with multiple subplots\n",
    "num_cols = 4\n",
    "num_rows = (len(train_df.columns) - 1) // num_cols + 1  # Exclude 'Attack' and compute number of required rows\n",
    "\n",
    "fig, ax = plt.subplots(nrows=num_rows, ncols=num_cols, figsize=(20, 5 * num_rows))  # Adjust size as needed\n",
    "plot_idx = list(itertools.product(range(num_rows), range(num_cols)))\n",
    "\n",
    "# Plot each feature except 'Attack'\n",
    "for idx, c in zip(plot_idx, [col for col in train_df.columns if col != 'Attack']):\n",
    "    if idx[0] == num_rows - 1 and idx[1] >= (len(train_df.columns) - 1) % num_cols:\n",
    "        fig.delaxes(ax[idx[0]][idx[1]])  # Remove unused axes\n",
    "    else:\n",
    "        sns.boxplot(x='Attack', y=c, data=train_df, ax=ax[idx[0]][idx[1]])\n",
    "        ax[idx[0]][idx[1]].set_title(c)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.pairplot(train_df[['Flow Duration', 'Protocol', 'ACK Flag Count', 'Attack']], hue='Attack')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# filtered features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "selected_features = [\n",
    "    # also integrated results from random forest model:\n",
    "    # IAT features\n",
    "    'Fwd IAT Total', 'Fwd IAT Mean', 'Fwd IAT Std', 'Fwd IAT Max', 'Fwd IAT Min',\n",
    "    'Bwd IAT Total', 'Bwd IAT Mean', 'Bwd IAT Std', 'Bwd IAT Max', 'Bwd IAT Min',\n",
    "    # Flow features\n",
    "    'Flow Duration', 'Fwd IAT Total',\n",
    "    'Flow Bytes/s', 'Flow Packets/s', 'Flow IAT Mean', 'Flow IAT Std', 'Flow IAT Max', 'Flow IAT Min',\n",
    "    # Packet Length Features\n",
    "    'Fwd Packet Length Min', 'Fwd Packets Length Total', 'Fwd Packet Length Max', 'Fwd Packet Length Mean',\n",
    "    'Bwd Packet Length Max', 'Bwd Packet Length Min', 'Bwd Packet Length Mean', 'Bwd Packet Length Std',\n",
    "    'Bwd Packets Length Total', 'Bwd Packet Length Max', 'Bwd Packets/s',\n",
    "    'Packet Length Min', 'Packet Length Max', 'Packet Length Mean', 'Packet Length Std', 'Packet Length Variance',\n",
    "    'Total Fwd Packets', 'Total Backward Packets',\n",
    "    # Additional selected features\n",
    "    'Avg Packet Size', 'Fwd Act Data Packets', 'FIN Flag Count', 'ACK Flag Count', \n",
    "    'Init Fwd Win Bytes', 'Init Bwd Win Bytes',  'Protocol', 'Down/Up Ratio',  'Fwd Header Length',\n",
    "    'Avg Fwd Segment Size','Avg Bwd Segment Size',\n",
    "    'Bwd Header Length',\n",
    "    # Attack\n",
    "    'Attack'\n",
    "]\n",
    "\n",
    "# Create a new dataframe with only the selected features\n",
    "train_df = train_df[selected_features]\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train_df.drop(['Attack'], axis=1)\n",
    "y_train = train_df['Attack']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit a Random Forest to get feature importances\n",
    "forest = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "forest.fit(X_train, y_train)\n",
    "\n",
    "# Select features based on importance weights\n",
    "model = SelectFromModel(forest, prefit=True, threshold='mean')  # selecting features with importance greater than the mean importance\n",
    "X_reduced = model.transform(X_train)\n",
    "# Convert X_reduced back to a DataFrame for better usability\n",
    "#X_reduced_df = pd.DataFrame(X_reduced, columns=X_train)\n",
    "\n",
    "# See which features were selected\n",
    "selected_features = X_train.columns[model.get_support()]\n",
    "print(\"Selected features:\", selected_features)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_importances = forest.feature_importances_\n",
    "indices = np.argsort(feature_importances)[::-1]  # Sort feature importances in descending order\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.title(\"Feature importances\")\n",
    "plt.bar(range(X_train.shape[1]), feature_importances[indices], align=\"center\")\n",
    "plt.xticks(range(X_train.shape[1]), X_train.columns[indices], rotation=90)\n",
    "plt.xlim([-1, X_train.shape[1]])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_importances = forest.feature_importances_\n",
    "indices = np.argsort(feature_importances)[::-1]  # Sort feature importances in descending order\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.title(\"Feature importances\")\n",
    "plt.bar(range(X_train.shape[1]), feature_importances[indices], align=\"center\")\n",
    "plt.xticks(range(X_train.shape[1]), X_train.columns[indices], rotation=90)\n",
    "plt.xlim([-1, X_train.shape[1]])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "with features reduced based on corr and boxplot:\n",
    "Selected features: = 14\n",
    "        'Index['Fwd IAT Total', 'Fwd IAT Mean', 'Bwd Packet Length Max',\n",
    "       'Bwd Packet Length Min', 'Bwd Packet Length Mean',\n",
    "       'Bwd Packet Length Std', 'Packet Length Max', 'Packet Length Mean',\n",
    "       'Packet Length Std', 'Packet Length Variance', 'Avg Packet Size',\n",
    "       'Init Fwd Win Bytes', 'Avg Bwd Segment Size', 'Avg Fwd Segment Size'],\n",
    "\n",
    "using all features:\n",
    "Selected features: = 28\n",
    "        ['Total Fwd Packets', 'Fwd Packets Length Total',\n",
    "       'Bwd Packets Length Total', 'Fwd Packet Length Max',\n",
    "       'Fwd Packet Length Mean', 'Bwd Packet Length Max',\n",
    "       'Bwd Packet Length Min', 'Bwd Packet Length Mean',\n",
    "       'Bwd Packet Length Std', 'Flow IAT Std', 'Fwd IAT Total',\n",
    "       'Fwd IAT Mean', 'Fwd IAT Max', 'Fwd IAT Min', 'Fwd Header Length',\n",
    "       'Bwd Header Length', 'Bwd Packets/s', 'Packet Length Max',\n",
    "       'Packet Length Mean', 'Packet Length Std', 'Packet Length Variance',\n",
    "       'Avg Packet Size', 'Avg Fwd Segment Size', 'Avg Bwd Segment Size',\n",
    "       'Subflow Fwd Bytes', 'Subflow Bwd Bytes', 'Init Fwd Win Bytes',\n",
    "       'Init Bwd Win Bytes'],\n",
    "\n",
    "using features from pre-select and rf: = 15\n",
    "        Index(['Fwd IAT Total', 'Fwd Packet Length Max', 'Bwd Packet Length Max',\n",
    "        'Bwd Packet Length Mean', 'Bwd Packet Length Std',\n",
    "        'Bwd Packets Length Total', 'Bwd Packet Length Max',\n",
    "        'Packet Length Max', 'Packet Length Mean', 'Packet Length Std',\n",
    "        'Packet Length Variance', 'Avg Packet Size', 'Fwd Header Length',\n",
    "        'Avg Fwd Segment Size', 'Avg Bwd Segment Size'],"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
